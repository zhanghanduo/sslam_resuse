%YAML:1.0

#common parameters
#support: 1 imu 1 cam; 1 imu 2 cam: 2 cam; 
imu: 0         
num_of_cam: 2
# Online set to 0 means offline processing to create a pose graph as prior map. (not guarantee realtime)
# Otherwise realtime online pose estimation with or without prior map
online: 1

# If cubicle set to 1, then you have to open cubicle_detect process to generate cubicle_topic in obstacle msgs format!
# Otherwise you will not be able to correctly start the system.
# We suggest set cubicle to 0 in open area or on low computation capability platform.
# Set to 1 in heavy traffic area.
cubicle: 0

# If gps_initial is set to 1, then the initial robot body pose is aligned with GPS pose at the initial moment, for visualization.
# Furthermore the pose graph saved has global information for better prior map use.
gps_initial: 1

# If gps_aid is set to 1, then the GPS realtime pose will be integrated into the system for better localization.
gps_aid: 0

imu_topic: ""
image0_topic: "/wide/left/image_raw"
image1_topic: "/wide/right/image_raw"
gps_topic: "/gps_pose"
cubicle_topic: ""
output_path: "/home/hd/output"

cam0_calib: "left_wide.yaml"
cam1_calib: "left_wide.yaml"
image_width: 640
image_height: 422
   

# Extrinsic parameter between IMU and Camera.
estimate_extrinsic: 0   # 0  Have an accurate extrinsic parameters. We will trust the following imu^R_cam, imu^T_cam, don't change it.
                        # 1  Have an initial guess about extrinsic parameters. We will optimize around your initial guess.

body_T_cam0: !!opencv-matrix
  rows: 4
  cols: 4
  dt: d
  data: [0.9999877641978028, -0.0005450290840269531, 0.004916746686278723, 0,
         0.0005329284451289657, 0.999996827066293, 0.002462081359130455, 0,
         -0.004918072991715405, -0.002459430959423314, 0.9999848817644214, 0,
         0, 0, 0, 1]

body_T_cam1: !!opencv-matrix
  rows: 4
  cols: 4
  dt: d
  data: [0.9998409420119342, 0.005051140797546275, -0.01710487221032119, 0.297378967897575,
         -0.005093218225300764, 0.9999841077713786, -0.00241729865541904, 0.00150234199657458,
         0.01709239025992324, 0.002504033011641428, 0.9998507788734672, -0.00508743844164699,
         0, 0, 0, 1]


#Multiple thread support
multiple_thread: 1
# Gpu acceleration support
use_gpu: 1
use_gpu_acc_flow: 1

#feature tracker parameters
max_cnt: 200            # max feature number in feature tracking
min_dist: 30            # min distance between two features 
freq: 0                # frequency (Hz) of publish tracking result. At least 10Hz for good estimation. If set 0, the frequency will be same as raw image
F_threshold: 1.0        # RANSAC threshold (pixel)
show_track: 1           # publish tracking image as topic
flow_back: 1            # perform forward and backward optical flow to improve feature tracking accuracy

#optimization parameters
max_solver_time: 0.08  # max solver iteration time (ms), to guarantee real time
max_num_iterations: 10   # max solver iteration, to guarantee real time
keyframe_parallax: 8.0 # keyframe selection threshold (pixel)

#loop closure parameters
load_previous_pose_graph: 0        # load and reuse previous pose graph; load from 'pose_graph_save_path'.
display_previous_trajectory: 0     # If load previous pose graph, option whether display the previous trajectory.
pose_graph_save_path: "/home/hd/output/pose_graph/" # save and load path
save_image: 0